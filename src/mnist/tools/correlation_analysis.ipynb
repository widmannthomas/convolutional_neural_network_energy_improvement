{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation analysis\n",
    "This Jupyter notebook can be used to analyze the measured data and calculate the correlation coefficients.<br>\n",
    "**Input:** Pruning and inference data as CSV. The inference data can be generated by using trace_analysis.jpynb.<br>\n",
    "**Output:** Complete dataset that contains pruning and inference information + correlation table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_unstructured_pruning_training_data = \"../../../src/mnist/train/models/unstructured_pruning/pruning.csv\"\n",
    "path_unstructured_pruning_speedup_training_data = \"../../../src/mnist/train/models/unstructured_pruning/pruning.csv\"\n",
    "path_structured_pruning_training_data = \"../../../src/mnist/train/models/structured_pruning/pruning.csv\"\n",
    "path_unstructured_pruning_inference_data = \"../../../src/mnist/train/models/unstructured_pruning/inference.csv\"\n",
    "path_unstructured_pruning_speedup_inference_data = \"../../../src/mnist/train/models/unstructured_pruning/inference_speedup.csv\"\n",
    "path_structured_pruning_inference_data = \"../../../src/mnist/train/models/structured_pruning/inference.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unstructured_pruning_training = pd.read_csv(path_unstructured_pruning_training_data, sep=';')\n",
    "df_unstructured_pruning_speedup_training = pd.read_csv(path_unstructured_pruning_speedup_training_data, sep=';')\n",
    "df_structured_pruning_training = pd.read_csv(path_structured_pruning_training_data, sep=';')\n",
    "df_unstructured_pruning_inference = pd.read_csv(path_unstructured_pruning_inference_data, sep=';')\n",
    "df_unstructured_pruning_speedup_inference = pd.read_csv(path_unstructured_pruning_speedup_inference_data, sep=';')\n",
    "df_structured_pruning_inference = pd.read_csv(path_structured_pruning_inference_data, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge training and inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unstructured_pruning = pd.concat([df_unstructured_pruning_training, df_unstructured_pruning_inference[[\"energyJoule\", \"duration\", \"energyJouleStd\", \"durationStd\"]]], axis=1)\n",
    "df_unstructured_pruning_speedup = pd.concat([df_unstructured_pruning_speedup_training, df_unstructured_pruning_speedup_inference[[\"energyJoule\", \"duration\", \"energyJouleStd\", \"durationStd\"]]], axis=1)\n",
    "df_structured_pruning = pd.concat([df_structured_pruning_training, df_structured_pruning_inference[[\"energyJoule\", \"duration\", \"energyJouleStd\", \"durationStd\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_tex(df, path):\n",
    "    df_latex = df[[\"CRPercent\", \"loss\", \"accuracy\", \"size\", \"parameters\", \"energyJoule\", \"duration\"]].copy()\n",
    "    df_latex.loc[:,'CRPercent'] *= 100\n",
    "    df_latex.loc[:,'accuracy'] *= 100\n",
    "    df_latex.loc[:,'energyJoule'] *= 1000\n",
    "    df_latex.to_latex(buf=path, index=None, header=[\"CR [%]\", \"Loss\", \"Accuracy [%]\", \"Size [Bytes]\", \"Parameters\", \"Energy [mJ]\", \"Duration [s]\"], float_format=lambda x: '%10.2f' % x)\n",
    "\n",
    "\n",
    "def save_corr_as_tex(df_latex, path):\n",
    "    df_latex.to_latex(buf=path, index=None, header=[\"CR [%]\", \"Energy [mJ]\", \"Duration [s]\", \"Loss\", \"Accuracy [%]\"], float_format=lambda x: '%10.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unstructured_pruning.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unstructured_pruning.to_csv(path_or_buf=\"../../../src/mnist/train/models/unstructured_pruning/pruning_and_inference.csv\", sep=';', index=None)\n",
    "save_as_tex(df_unstructured_pruning, \"../../../src/mnist/train/models/unstructured_pruning/pruning_and_inference.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_structured_pruning.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_structured_pruning.to_csv(path_or_buf=\"../../../src/mnist/train/models/structured_pruning/pruning_and_inference.csv\", sep=';', index=None)\n",
    "save_as_tex(df_structured_pruning, \"../../../src/mnist/train/models/structured_pruning/pruning_and_inference.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unstructured_pruning_speedup.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unstructured_pruning_speedup.to_csv(path_or_buf=\"../../../src/mnist/train/models/unstructured_pruning/pruning_and_inference_speedup.csv\", sep=';', index=None)\n",
    "save_as_tex(df_unstructured_pruning_speedup, \"../../../src/mnist/train/models/unstructured_pruning/pruning_and_inference_speedup.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_unstructured_pruning.CRPercent, df_unstructured_pruning.accuracy)\n",
    "plt.plot(df_structured_pruning.CRPercent, df_structured_pruning.accuracy)\n",
    "plt.legend(['Unstructured','Structured'], title = \"Accuracy\")\n",
    "plt.xlabel(\"CR\")\n",
    "plt.ylabel(\"[%]\")\n",
    "plt.show()\n",
    "plt.plot(df_unstructured_pruning.CRPercent, df_unstructured_pruning.energyJoule)\n",
    "plt.plot(df_structured_pruning.CRPercent, df_structured_pruning.energyJoule)\n",
    "plt.plot(df_unstructured_pruning_speedup.CRPercent, df_unstructured_pruning_speedup.energyJoule)\n",
    "plt.legend(['Unstructured','Structured', 'Unstructured (speedup)'], title = \"Energy consumption\")\n",
    "plt.xlabel(\"CR\")\n",
    "plt.ylabel(\"[J]\")\n",
    "plt.show()\n",
    "plt.plot(df_unstructured_pruning.CRPercent, df_unstructured_pruning.duration)\n",
    "plt.plot(df_structured_pruning.CRPercent, df_structured_pruning.duration)\n",
    "plt.plot(df_unstructured_pruning_speedup.CRPercent, df_unstructured_pruning_speedup.duration)\n",
    "plt.legend(['Unstructured','Structured', 'Unstructured (speedup)'], title = \"Duration\")\n",
    "plt.xlabel(\"CR\")\n",
    "plt.ylabel(\"[s]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unstructured pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unstructured_with_baseline_corr = df_unstructured_pruning[[\"CRPercent\", \"energyJoule\", \"duration\", \"loss\", \"accuracy\"]].corr(method=\"pearson\")\n",
    "df_unstructured_with_baseline_corr.to_csv(path_or_buf=\"../../../src/mnist/train/models/unstructured_pruning/inference_corr.csv\", sep=';')\n",
    "save_corr_as_tex(df_unstructured_with_baseline_corr, \"../../../src/mnist/train/models/unstructured_pruning/inference_corr.tex\")\n",
    "df_unstructured_with_baseline_corr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_structured_with_baseline_corr = df_structured_pruning[[\"CRPercent\", \"energyJoule\", \"duration\", \"loss\", \"accuracy\"]].corr(method=\"pearson\")\n",
    "df_structured_with_baseline_corr.to_csv(path_or_buf=\"../../../src/mnist/train/models/structured_pruning/inference_corr.csv\", sep=';')\n",
    "save_corr_as_tex(df_structured_with_baseline_corr, \"../../../src/mnist/train/models/structured_pruning/inference_corr.tex\")\n",
    "df_structured_with_baseline_corr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unstructured pruning (speedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unstructured_with_baseline_speedup_corr = df_unstructured_pruning_speedup[[\"CRPercent\", \"energyJoule\", \"duration\", \"loss\", \"accuracy\"]].corr(method=\"pearson\")\n",
    "df_unstructured_with_baseline_speedup_corr.to_csv(path_or_buf=\"../../../src/mnist/train/models/unstructured_pruning/inference_speedup_corr.csv\", sep=';')\n",
    "save_corr_as_tex(df_unstructured_with_baseline_speedup_corr, \"../../../src/mnist/train/models/unstructured_pruning/inference_speedup_corr.tex\")\n",
    "df_unstructured_with_baseline_speedup_corr.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d1cd94cfed04ad9427ef807a2ad11acb0c84f064da073693db7977f8eb74254"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('test': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
